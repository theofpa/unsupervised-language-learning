{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, evaluate the three models in the word analogy task. Given an analogy $a : a∗ :: b :?$, the task is to find b∗.\n",
    "\n",
    "To solve the word analogy tasks with the given word embeddings, you should use the vector offset method based on the cosine distance. This means, to answer the question $a : a∗ :: b : b∗$, where b∗ is unknown, to find the embedding of b∗, we simply first compute the offset vector: $v = a ∗ −a$, next compute the vector representation of the word we expect: $b∗ = b + v$. Most probably, there is no word with the exact same vector we compute this way. Hence, retrieve the word which its vector representation is closer to predicted vector based on cosine distance. Note that, in this task it is important to normalize the word vectors to unit form.\n",
    "\n",
    "You need to report the accuracy and MRR (Mean Reciprocal Rank) of each of the word embedding models on this task. The accuracy is the percentage of the correctly answered questions from the word analogy question set.\n",
    "\n",
    "Again, in addition to the quantitative evaluation, conduct a qualitative anal- ysis of the differences between the three models. Include both in your report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load libraries and data\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import dask.dataframe as dd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_analogy=pd.read_csv('questions-words.txt', sep=' ', names=['wp1_1','wp1_2','wp2_1','wp2_2'])\n",
    "deps=pd.read_csv('deps.words', sep=' ', header=None, index_col=0, na_values='nowaytofindnan', keep_default_na=False)\n",
    "bow2=pd.read_csv('bow2.words', sep=' ', header=None, index_col=0, na_values='nowaytofindnan', keep_default_na=False)\n",
    "bow5=pd.read_csv('bow5.words', sep=' ', header=None, index_col=0, na_values='nowaytofindnan', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean-up data\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "deps.name='deps'\n",
    "bow2.name='bow2'\n",
    "bow5.name='bow5'\n",
    "\n",
    "google_analogy.drop(google_analogy[google_analogy['wp1_1']==':'].index, inplace=True)\n",
    "\n",
    "# Remove the words from the Google test set, which do not appear in the word embedings models\n",
    "for i in google_analogy.wp2_2.unique():\n",
    "    if i.lower() not in deps.index:\n",
    "        google_analogy=google_analogy[(google_analogy['wp2_2']!=i) & (google_analogy['wp1_2']!=i)]\n",
    "\n",
    "all_questions=len(google_analogy)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate accuracy and MRR\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy_rank(word1, word2, word3, word4, model):\n",
    "    emb1, emb2, emb3 = model.loc[word1], model.loc[word2], model.loc[word3]\n",
    "    model['cs']=cosine_similarity(model,(emb3+(emb2-emb1)).values.reshape(1,-1))\n",
    "    return int(model['cs'].rank(ascending=False)[word4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bow2 : Accuracy 10.62% -- MRR 0.3525\n",
      "bow5 : Accuracy 10.10% -- MRR 0.4011\n",
      "deps : Accuracy 3.54% -- MRR 0.2157\n",
      "CPU times: user 3h 41min 12s, sys: 3h 5min 15s, total: 6h 46min 27s\n",
      "Wall time: 44min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Calculate 10% of all Google test set questions\n",
    "subset=int(0.1*all_questions)\n",
    "for model in [bow2, bow5, deps]:\n",
    "    ga = dd.from_pandas(google_analogy.sample(subset), npartitions=6)\n",
    "    ga['rank']=ga.apply(lambda x: analogy_rank(x.wp1_1.lower(), x.wp1_2.lower(), x.wp2_1.lower(), x.wp2_2.lower(), model), axis=1)\n",
    "    accuracy=ga[ga['rank']==1]['rank'].count().compute()/subset\n",
    "    MRR=(1/ga['rank']).sum().compute()/subset\n",
    "    print(\"%s : Accuracy %.2f%% -- MRR %.4f\" % (model.name, 100*accuracy, MRR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
